{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MatthiasPICARD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import plotly\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_pinball_loss, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More informations about this dataset here :https://vitaldb.net/dataset/?query=overview#h.1fo5zknztqnw\n",
    "df = pd.read_csv(\"operation_length_predictions_vitalDB.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_duration_cols(df):\n",
    "    \"\"\"Calculate time durations for hospital, operation and anesthesia in hours from seconds\"\"\"\n",
    "    df['duration_stay'] = (df['dis'] - df['adm'])/3600\n",
    "    df['duration_operation'] = (df['opend'] - df['opstart'])/3600\n",
    "    df['duration_anesthesia'] = (df['aneend'] - df['anestart'])/3600\n",
    "    return df\n",
    "\n",
    "def drop_id_cols(df):\n",
    "    \"\"\"Drop ID columns and original timestamp columns\"\"\"\n",
    "    columns_to_drop = [\n",
    "        'subjectid',\n",
    "        'dis', 'adm',\n",
    "        'opend', 'opstart',\n",
    "        'aneend', 'anestart',\n",
    "        'casestart','caseend', \n",
    "        'icu_days',\"dx\",\"opname\",\n",
    "        'preop_ecg','preop_ph', 'preop_hco3', 'preop_be', 'preop_pao2', \n",
    "        'preop_paco2', 'preop_sao2', 'cormack', 'tubesize',\n",
    "        'dltubesize', 'lmasize', 'iv2', 'aline1', 'aline2',\n",
    "        'cline1', 'cline2',\"preop_na\",\"preop_k\",'airway','iv1','duration_stay',\n",
    "        'death_inhosp'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=df.filter(like='intraop').columns)\n",
    "\n",
    "    return df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "def map_position(df):\n",
    "    position_mapping = {\n",
    "    'Supine': 'Supine',\n",
    "    'Lithotomy': 'Lithotomy',\n",
    "    'Left lateral decubitus': 'Lateral Decubitus',\n",
    "    'Right lateral decubitus': 'Lateral Decubitus',\n",
    "    'Prone': 'Prone',\n",
    "    'Reverse Trendelenburg': 'Trendelenburg (Inclined)',\n",
    "    'Trendelenburg': 'Trendelenburg (Inclined)',\n",
    "    'Sitting': 'Sitting',\n",
    "    'Left kidney': 'Lateral Decubitus',\n",
    "    'Right kidney': 'Lateral Decubitus'\n",
    "    }\n",
    "\n",
    "    df['position'] = df['position'].map(position_mapping)\n",
    "    return df\n",
    "\n",
    "def map_ane_type(df):\n",
    "    ane_mapping = {\n",
    "        'General': 'General Anesthesia',\n",
    "        'Spinal': 'Regional Anesthesia',\n",
    "        'Sedationalgesia': 'Regional Anesthesia'\n",
    "    }\n",
    "\n",
    "    df['ane_type'] = df['ane_type'].map(ane_mapping)\n",
    "    return df\n",
    "\n",
    "def handle_age_more_than_89(df):\n",
    "    df.loc[df['age'] == '>89', 'age'] = 92\n",
    "    return df\n",
    "\n",
    "def map_preop_pft(df):\n",
    "    pft_mapping = {\n",
    "    \"Normal\": \"Normal\",\n",
    "    \"Mild obstructive\": \"Mild/Moderate Obstructive\",\n",
    "    \"Moderate obstructive\": \"Mild/Moderate Obstructive\",\n",
    "    \"Borderline obstructive\": \"Mild/Moderate Obstructive\",\n",
    "    \"Severe obstructive\": \"Severe Obstructive\",\n",
    "    \"Mixed or pure obstructive\": \"Severe Obstructive\",\n",
    "    \"Mild restrictive\": \"Mild/Moderate Restrictive\",\n",
    "    \"Moderate restrictive\": \"Mild/Moderate Restrictive\",\n",
    "    \"Severe restrictive\": \"Severe Restrictive\",\n",
    "    }\n",
    "    df['preop_pft'] = df['preop_pft'].map(pft_mapping)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def drop_na_rows(df):\n",
    "    return df.dropna().reset_index(drop=True)\n",
    "\n",
    "def encode_scale(df):\n",
    "    # label_encoder = OrdinalEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # categorical_features = []\n",
    "    numerical_features = ['age', 'weight','height', 'bmi', 'asa', 'preop_hb', 'preop_plt', 'preop_pt', 'preop_aptt', 'preop_gluc', 'preop_alb', 'preop_ast', 'preop_alt', 'preop_bun','preop_cr']\n",
    "    onehot_features = ['preop_pft','sex', 'department', 'optype', 'approach', 'ane_type', 'position']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('cat', label_encoder, categorical_features),\n",
    "        ('num', scaler, numerical_features),\n",
    "        ('onehot', onehot_encoder, onehot_features)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    # verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    save_path = 'preprocessor.pkl'\n",
    "    df_processed = preprocessor.fit_transform(df)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(preprocessor, f)\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "def load_and_apply_transformers(df, save_path='preprocessor.pkl'):\n",
    "    with open(save_path, 'rb') as f:\n",
    "        preprocessor = pickle.load(f)\n",
    "\n",
    "    df_processed = preprocessor.transform(df)\n",
    "    return df_processed\n",
    "\n",
    "def split_dataset(df,target_column='duration_anesthesia'):\n",
    "    \"\"\"Split the dataset into train and test sets\"\"\"\n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=['duration_operation','duration_anesthesia'], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def handle_outliers(X_train,y_train,target_column):\n",
    "    \"\"\"Handle outliers in the training set\"\"\"\n",
    "    df = pd.concat([X_train, y_train], axis=1)\n",
    "    df = df.drop(df[df[target_column] > 10].index)\n",
    "    df = df.drop(df[df[target_column] < 0].index)\n",
    "\n",
    "    y_train = df[target_column]\n",
    "    X_train = df.drop(columns=[target_column], axis=1)\n",
    "    # print(X_train.shape)\n",
    "    return X_train,y_train\n",
    "\n",
    "def process_data(df,target_column):\n",
    "    \"\"\"Main function to process the dataframe\"\"\"\n",
    "    df = calculate_duration_cols(df)\n",
    "    df = drop_id_cols(df)\n",
    "    df = drop_na_rows(df)\n",
    "    df = map_position(df)\n",
    "    df = map_ane_type(df)\n",
    "    df = handle_age_more_than_89(df)\n",
    "    df = map_preop_pft(df)\n",
    "\n",
    "    sample = df[df[\"caseid\"]<6]\n",
    "    df = df[df[\"caseid\"]>6]\n",
    "    df = df.drop(columns=['caseid'], axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df,target_column)\n",
    "    X_train, y_train = handle_outliers(X_train,y_train,target_column)\n",
    "    X_train = encode_scale(X_train)\n",
    "    X_test = load_and_apply_transformers(X_test)\n",
    "    return X_train, X_test, y_train, y_test,sample\n",
    "\n",
    "X_train, X_test, y_train, y_test,sample = process_data(df, target_column='duration_anesthesia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:27:13,402] A new study created in memory with name: no-name-eb5ce4d0-84e2-40a2-8ce2-281b277dfa4c\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.291782:  10%|█         | 1/10 [00:38<05:43, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:27:51,527] Trial 0 finished with value: 0.2917823334336045 and parameters: {'learning_rate': 0.1819628298284298, 'n_estimators': 187, 'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 3, 'subsample': 0.7030759383742439}. Best is trial 0 with value: 0.2917823334336045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  20%|██        | 2/10 [01:25<05:47, 43.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:28:38,698] Trial 1 finished with value: 0.2746290274606374 and parameters: {'learning_rate': 0.07613678598124894, 'n_estimators': 493, 'max_depth': 2, 'min_samples_leaf': 15, 'min_samples_split': 9, 'subsample': 0.7773509322177742}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  30%|███       | 3/10 [03:06<08:09, 69.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:30:20,191] Trial 2 finished with value: 0.2774683699823887 and parameters: {'learning_rate': 0.06241041446639623, 'n_estimators': 475, 'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 4, 'subsample': 0.7777422149355829}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  40%|████      | 4/10 [03:53<06:05, 60.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:31:07,200] Trial 3 finished with value: 0.2836538744799744 and parameters: {'learning_rate': 0.1277836732519097, 'n_estimators': 154, 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 8, 'subsample': 0.6903760139383015}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  50%|█████     | 5/10 [04:40<04:39, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:31:54,296] Trial 4 finished with value: 0.27830414183134855 and parameters: {'learning_rate': 0.05287140254959532, 'n_estimators': 489, 'max_depth': 2, 'min_samples_leaf': 3, 'min_samples_split': 4, 'subsample': 0.7967048169013556}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  60%|██████    | 6/10 [04:58<02:51, 42.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:32:11,653] Trial 5 finished with value: 0.27733808413053984 and parameters: {'learning_rate': 0.1086368819906108, 'n_estimators': 105, 'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 15, 'subsample': 0.6025359063096482}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  70%|███████   | 7/10 [06:10<02:37, 52.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:33:23,712] Trial 6 finished with value: 0.2947992105809126 and parameters: {'learning_rate': 0.276461043693947, 'n_estimators': 362, 'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 13, 'subsample': 0.9952381997555114}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  80%|████████  | 8/10 [06:38<01:29, 44.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:33:51,439] Trial 7 finished with value: 0.2809682457061863 and parameters: {'learning_rate': 0.27956784777862637, 'n_estimators': 153, 'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 10, 'subsample': 0.8339031387028691}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629:  90%|█████████ | 9/10 [07:33<00:47, 47.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:34:46,768] Trial 8 finished with value: 0.2772081296634074 and parameters: {'learning_rate': 0.03534030369582784, 'n_estimators': 381, 'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 5, 'subsample': 0.9747190010767901}. Best is trial 1 with value: 0.2746290274606374.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.274629: 100%|██████████| 10/10 [08:26<00:00, 50.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:35:40,304] Trial 9 finished with value: 0.2914749157566596 and parameters: {'learning_rate': 0.24072063157120419, 'n_estimators': 240, 'max_depth': 5, 'min_samples_leaf': 15, 'min_samples_split': 9, 'subsample': 0.7342162617918062}. Best is trial 1 with value: 0.2746290274606374.\n",
      "Best parameters: {'learning_rate': 0.07613678598124894, 'n_estimators': 493, 'max_depth': 2, 'min_samples_leaf': 15, 'min_samples_split': 9, 'subsample': 0.7773509322177742}\n",
      "\n",
      "Model Evaluation:\n",
      "Pinball Loss: 0.3048\n",
      "Coverage (should be close to 0.90): 0.8614\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X, y, n_splits=4):\n",
    "    \"\"\"Optuna objective function with cross-validation for 0.90 quantile\"\"\"\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 6),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 3, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    }\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_fold_train, X_fold_val = X[train_idx], X[val_idx]\n",
    "        y_fold_train, y_fold_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Train model for 90th percentile\n",
    "        model = GradientBoostingRegressor(\n",
    "            loss=\"quantile\",\n",
    "            alpha=0.90,\n",
    "            random_state=42,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        # Fit and evaluate\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate pinball loss\n",
    "        score = mean_pinball_loss(y_fold_val, y_pred, alpha=0.90)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_and_train_model(X_train, y_train, n_trials=10):\n",
    "    \"\"\"Optimize hyperparameters and return the best model\"\"\"\n",
    "    # Create study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    # Optimize\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), \n",
    "                  n_trials=n_trials,\n",
    "                  show_progress_bar=True)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = study.best_params\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    final_model = GradientBoostingRegressor(\n",
    "        loss=\"quantile\",\n",
    "        alpha=0.90,\n",
    "        random_state=42,\n",
    "        **best_params\n",
    "    )\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    return final_model, study,best_params\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    pinball_loss = mean_pinball_loss(y_test, y_pred, alpha=0.90)\n",
    "    \n",
    "    # Calculate percentage of predictions above actual values\n",
    "    coverage = np.mean(y_test <= y_pred)\n",
    "    \n",
    "    return {\n",
    "        'pinball_loss': pinball_loss,\n",
    "        'coverage': coverage\n",
    "    }\n",
    "\n",
    "X_train_array = np.array(X_train)\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "best_model, study,best_params = optimize_and_train_model(\n",
    "    X_train_array, \n",
    "    y_train_array, \n",
    "    n_trials=10\n",
    ")\n",
    "\n",
    "metrics = evaluate_model(best_model, X_test, y_test)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"Pinball Loss: {metrics['pinball_loss']:.4f}\")\n",
    "print(f\"Coverage (should be close to 0.90): {metrics['coverage']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on all datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_upper_quantile_model(X_full, y_full):\n",
    "    \"\"\"Train a single Gradient Boosting model for 0.90 quantile\"\"\"\n",
    "    model = GradientBoostingRegressor(\n",
    "        loss=\"quantile\",\n",
    "        alpha=0.9,\n",
    "        **best_params # best params identified during the tuning procedure\n",
    "    )\n",
    "    model.fit(X_full, y_full)\n",
    "    return model\n",
    "\n",
    "# Combine training and test data\n",
    "X_full = np.concatenate([X_train, X_test], axis=0)\n",
    "y_full = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "# Train model\n",
    "upper_model = train_upper_quantile_model(X_full, y_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quantile_model_90.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(upper_model, 'quantile_model_90.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pipeline(loaded_model,data):\n",
    "    preprocessed_data = load_and_apply_transformers(data)\n",
    "    print(preprocessed_data.shape)\n",
    "    predictions = loaded_model.predict(preprocessed_data)\n",
    "    return predictions,preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 51)\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample.csv\")\n",
    "sample_curated = sample.drop(columns=[\"caseid\",\"duration_operation\",\"duration_anesthesia\"])\n",
    "loaded_model = joblib.load('quantile_model_90.joblib')\n",
    "predictions,preprocessed_data = inference_pipeline(loaded_model,sample_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.98828159, 5.69069783, 4.58451962, 5.80180341, 5.34543765])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.166667\n",
       "1    4.433333\n",
       "2    1.333333\n",
       "3    5.833333\n",
       "4    6.500000\n",
       "Name: duration_anesthesia, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['duration_anesthesia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3400999237599428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pinball_loss(sample['duration_anesthesia'], predictions, alpha=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quantile_model_90.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(upper_model, 'quantile_model_90.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
